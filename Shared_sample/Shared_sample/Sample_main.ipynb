{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Replace / with \\ if running on windows and make sure to install all dependencies\n",
    "# To test on other models --- select the model you wish\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "from tqdm import tqdm    \n",
    "\n",
    "from termcolor import colored\n",
    "import tensorflow as tf\n",
    "import os                   # work with directories\n",
    "import numpy as np          # dealing with arrays\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tfe = tf.contrib.eager\n",
    "import pickle as pk\n",
    "import sys\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.python.eager import tape\n",
    "import  cv2\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "layers = tf.keras.layers\n",
    "tf.enable_eager_execution(config=config)\n",
    "tf.executing_eagerly()\n",
    "print(tf.__version__)\n",
    "\n",
    "HOME_DIR = os.getcwd()\n",
    "MAIN_dir = HOME_DIR + '/Cleaned_code/Shared_git/'\n",
    "checkpoint_path = MAIN_dir + 'checkpoints/'\n",
    "data_files_path = MAIN_dir + 'data_files/'\n",
    "mean_path = data_files_path + 'std_mean_60_dataset.npy'\n",
    "dataset_path = MAIN_dir + 'dataset/'\n",
    "tensorboard_path = MAIN_dir + 'tensorboard/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'sample_set.pickle'\n",
    "pickle_in_sample = open(MAIN_dir + 'data_files/' + filename, \"rb\")\n",
    "sample_data = pk.load(pickle_in_sample)\n",
    "pickle_in_sample.close()\n",
    "\n",
    "images = sample_data['images']\n",
    "labels = sample_data['labels']\n",
    "speeds = sample_data['speeds']\n",
    "log_length = sample_data['log_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 8\n",
    "Buffer_size = 8\n",
    "Epochs = 100\n",
    "\n",
    "sample_dataset = tf.data.Dataset.from_tensor_slices((images, labels, speeds, log_length))\n",
    "sample_dataset = sample_dataset.batch(Batch_size)\n",
    "sample_dataset = sample_dataset.prefetch(Batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RES-9ER - default  -- choose path\n",
    "# To test on other models --- select the model you wish\n",
    "Network_size = None  # Set to default RES-9ER\n",
    "data_format = 'channels_last'\n",
    "if Network_size ==16:\n",
    "    from Shared_git.models import RES_16E as Res9  \n",
    "    model = Res9.Res16E(data_format=data_format, include_top=True, pooling=None, classes=1)\n",
    "elif Network_size == 9:\n",
    "    from Shared_git.models import RES_9E as Res9  \n",
    "    model = Res9.Res9E(data_format=data_format, include_top=True, pooling=None, classes=1)\n",
    "else:\n",
    "    from Shared_git.models import RES_9ER as Res9\n",
    "    model = Res9.Res9ER(data_format=data_format, include_top=True, pooling=None, classes=1)\n",
    "    # Instantiate the model and configure tensorbaord and checkpoints\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "accuracy = 0 \n",
    "acc_prediction = tf.constant(0, dtype=\"float32\")\n",
    "t = tf.constant(1/7.5, dtype=\"float32\")\n",
    "loss = tf.constant(0, dtype=\"float32\")\n",
    "logdir = tensorboard_path\n",
    "checkpont_path = checkpoint_path+\"cp-{log:06d}.ckpt\"\n",
    "checkpont_dir = os.path.dirname(checkpoint_path)\n",
    "summary_writer = tf.contrib.summary.create_file_writer(logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7fd21c52c358>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD checkpoint if you wish to test results   -- can select other check points based on selected model\n",
    "checkpoint_name = 'RES_9ER'\n",
    "model.load_weights(checkpoint_path+checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(prediction, label, train_log_length_, operation='L2'):\n",
    "    if operation == 'L2':\n",
    "        return tf.divide(tf.squared_difference(prediction, label), train_log_length_)\n",
    "    elif operation == 'Subtraction':\n",
    "        return tf.divide(tf.subtract(prediction, label), train_log_length_)\n",
    "    elif operation == 'L1':\n",
    "        return tf.divide(tf.abs(tf.subtract(prediction, label)), train_log_length_)\n",
    "    else:\n",
    "        raise ValueError('Please specify loss function (L2, L1, Subtraction)')\n",
    "\n",
    "\n",
    "def print_progress(count, total, cnt, overall, time_, count_log, loss, loss_):\n",
    "    percent_complete = float(count) / total\n",
    "    overall_complete = float(cnt) / (overall-1)\n",
    "\n",
    "    sec = time_ % 60\n",
    "    mint = int(time_/60) % 60\n",
    "    hr = int(time_/3600) % 60\n",
    "    loss = str(loss)\n",
    "    loss_ = str(loss_)\n",
    "    msg = \"\\r Time_lapsed (hr:mm:ss) --> {0:02d}:{1:02d}:{2:02d} ,   loss: {3:s}   Log Progress: {4:.1%},     Overall Progress:{5:.1%},\" \\\n",
    "        \" completed {6:d} out of 185 logs <--> Initial loss: {7:s} \".format(hr, mint, sec, loss, percent_complete, overall_complete, count_log, loss_)\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "\n",
    "def validation_progress(log_cnt, num_logs, time_, loss, accuracy_loc):\n",
    "    log_cnt += 1\n",
    "    overall_complete = float(log_cnt) / num_logs\n",
    "    sec = int(time_) % 60\n",
    "    mint = int(time_/60) % 60\n",
    "    hr = int(time_/3600) % 60\n",
    "    loss = str(loss)\n",
    "    msg = \"\\r Validation_Time (hr:mm:ss) --> {0:02d}:{1:02d}:{2:02d} ,   Avg_loss: {3:s}   Avg_accuracy: {4:.1%}   Overall Progress:{5:.1%},\" \\\n",
    "        \" completed {6:d} out of {7:d} logs\".format(hr, mint, sec, loss, accuracy_loc, overall_complete, log_cnt, num_logs)\n",
    "    sys.stdout.write(colored(msg, 'green'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def write_summaries(loss, i, global_step, vars_loc, grads_loc, train=True):\n",
    "    with summary_writer.as_default():\n",
    "        with tf.contrib.summary.always_record_summaries():\n",
    "            if train:\n",
    "                tf.contrib.summary.scalar(\"train_loss\", loss, step=global_step)\n",
    "                tf.contrib.summary.scalar(\"step\", i, step=global_step)\n",
    "                #  do not add spaces after names\n",
    "                tf.contrib.summary.histogram(\"weights\", vars_loc, step=global_step)\n",
    "                tf.contrib.summary.histogram(\"gradients\", grads_loc, step=global_step)\n",
    "            else:\n",
    "                tf.contrib.summary.scalar(\"val_loss\", loss, step=global_step)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION CODE\n",
    "\n",
    "def validate_model(model_loc, val_step_, n_logs, data_set, write_summary=True, return_losses=True):\n",
    "    logs_N = n_logs\n",
    "    start = time.time()\n",
    "    MAE = []\n",
    "    MSE = []\n",
    "    MSBE = []\n",
    "    log_order = []\n",
    "    Accuracy = []\n",
    "    metric_mse = []\n",
    "    summed_volume = 0\n",
    "    remainder = 0\n",
    "    iterations = 0\n",
    "    fixed_size = 0\n",
    "    count = 0\n",
    "    new_log = True\n",
    "    cnt_log = -1\n",
    "    signal = []\n",
    "    signals = [] \n",
    "    for (batch, (image, label, speed, lengths)) in (enumerate(data_set)):\n",
    "        size = np.shape(label)[0]\n",
    "        labels = tf.reshape(label, [size, 1])\n",
    "        speeds = tf.reshape(speed, [size, 1])\n",
    "        log_length = tf.squeeze(lengths)\n",
    "        images = tf.squeeze(image)\n",
    "        batch += 1\n",
    "        if new_log:           \n",
    "            new_log = False\n",
    "            length = int(log_length[0].numpy() - fixed_size + remainder)\n",
    "            iterations = int(np.floor(length/Batch_size))\n",
    "            remainder = int(np.mod(length, Batch_size))\n",
    "            fixed_size = np.shape(speeds)[0]\n",
    "            cnt_log += 1\n",
    "\n",
    "        if count < iterations:\n",
    "            mass_pred = model_loc(images)\n",
    "            volume = (mass_pred * speeds) * t\n",
    "            summed_volume += tf.reduce_sum(volume)\n",
    "            mass = np.abs(summed_volume.numpy())\n",
    "            count = count + 1\n",
    "            signal.append(volume)\n",
    "            # Compute loss\n",
    "            if count == iterations and remainder == 0:\n",
    "                loss_unsigned = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L2').numpy())\n",
    "                loss_outlier = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L1').numpy())\n",
    "                loss_signed = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='Subtraction').numpy())\n",
    "                MSE.append(loss_unsigned)\n",
    "                MAE.append(loss_outlier)\n",
    "                MSBE.append(loss_signed)\n",
    "                signals.append(signal[0:len(signal)])\n",
    "                signal.clear()\n",
    "        \n",
    "                gt = np.squeeze(labels[0].numpy())\n",
    "                metric_mse.append(loss_unsigned)\n",
    "                \n",
    "                tmp = np.abs(gt - mass)\n",
    "                tmp = tmp / gt\n",
    "                log_acc = 1 - np.squeeze(tmp)\n",
    "                    \n",
    "                Accuracy.append(log_acc)\n",
    "                log_order.append(np.squeeze(log_length[0].numpy()))\n",
    "                time_ = time.time() - start\n",
    "                validation_progress(cnt_log, logs_N, time_, np.mean(metric_mse), np.mean(Accuracy))\n",
    "                if write_summary:\n",
    "                    write_summaries(np.mean(MSE), 0, val_step_, 0, 0, train=False)\n",
    "                val_step_ += 1\n",
    "                # Reset\n",
    "                summed_volume = 0\n",
    "                count = 0\n",
    "                fixed_size = 0\n",
    "                new_log = True\n",
    "        # Handle the remainder from iterations\n",
    "        else:\n",
    "            # Compute and Aggregate the remainder Gradients\n",
    "            mass_pred = model(images[0:remainder])\n",
    "            volume = (mass_pred * speeds[0:remainder]) * t\n",
    "            summed_volume += tf.reduce_sum(volume)\n",
    "            mass = np.abs(summed_volume.numpy())\n",
    "            signal.append(volume)\n",
    "            \n",
    "            loss_unsigned = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L2').numpy())\n",
    "            loss_outlier = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L1').numpy())\n",
    "            loss_signed = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='Subtraction').numpy())\n",
    "            MSE.append(loss_unsigned)\n",
    "            MAE.append(loss_outlier)\n",
    "            MSBE.append(loss_signed)\n",
    "            signals.append(signal[0:len(signal)])\n",
    "            signal.clear()\n",
    "            \n",
    "            gt = np.squeeze(labels[0].numpy())\n",
    "            metric_mse.append(loss_unsigned)\n",
    "\n",
    "            tmp = np.abs(gt - mass)\n",
    "            tmp = tmp / gt\n",
    "            log_acc = 1 - np.squeeze(tmp)\n",
    "            \n",
    "            Accuracy.append(log_acc)\n",
    "            log_order.append(np.squeeze(log_length[0].numpy()))\n",
    "            time_ = time.time() - start\n",
    "            validation_progress(cnt_log, logs_N, time_, np.mean(metric_mse), np.mean(Accuracy))  \n",
    "            \n",
    "            if write_summary:  \n",
    "                write_summaries(np.mean(MSE), 0, val_step_, 0, 0, train=False)\n",
    "            val_step_ += 1\n",
    "            summed_volume = 0\n",
    "            count = 0\n",
    "            new_log = True\n",
    "            \n",
    "            # Handle gradients for the next log\n",
    "            if cnt_log != logs_N-1:    \n",
    "                mass_pred = model(images[remainder:])\n",
    "                volume = (mass_pred * speeds[remainder:]) * t\n",
    "                summed_volume += tf.reduce_sum(volume)\n",
    "                signal.append(volume)\n",
    "                \n",
    "    if return_losses:\n",
    "        return MSE, MAE, MSBE, Accuracy, val_step_\n",
    "    else: \n",
    "        return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING CODE  -- or move the following cell if you just wish to test results and make plots \n",
    "save_epoch = 1\n",
    "init_vol = 0\n",
    "summed_vol_diff = 0\n",
    "volume_diff = []\n",
    "aggregated_diff = []\n",
    "lamda = 0.05\n",
    "loss_ = 0\n",
    "logs_N = 1\n",
    "start = time.time()\n",
    "aggregated = []\n",
    "MSE_log = []\n",
    "MAE_log = []\n",
    "MSBE_log = []\n",
    "MSE_t = []\n",
    "MAE_t = []\n",
    "MSBE_t = []\n",
    "MSE_avg = []\n",
    "MAE_avg = []\n",
    "MSBE_avg = []\n",
    "MSE_train = []\n",
    "val_step = 1\n",
    "run_name = 'random'\n",
    "performance_flag = True\n",
    "for epoch in range(Epochs):\n",
    "    loss_metric = 0\n",
    "    summed_volume = 0\n",
    "    remainder = 0\n",
    "    iterations = 0\n",
    "    fixed_size = 0\n",
    "    count = 0\n",
    "    new_log = True\n",
    "    append_flag = True\n",
    "    next_log = False\n",
    "    cnt_log = -1\n",
    "    first_run = True    \n",
    "    for (batch, (image, label, speed, lengths)) in (enumerate(sample_dataset)):\n",
    "        size = np.shape(label)[0]\n",
    "        labels = tf.reshape(label, [size, 1])\n",
    "        speeds = tf.reshape(speed, [size, 1])\n",
    "        log_length = tf.squeeze(lengths)\n",
    "        images = tf.squeeze(image)\n",
    "        batch += 1\n",
    "        step = tf.train.get_or_create_global_step()\n",
    "        if new_log:           \n",
    "            new_log = False\n",
    "            length = int(log_length[0].numpy() - fixed_size + remainder)\n",
    "            iterations = int(np.floor(length/Batch_size))\n",
    "            remainder = int(np.mod(length, Batch_size))\n",
    "            fixed_size = np.shape(speeds)[0]\n",
    "            cnt_log += 1\n",
    "\n",
    "        if count < iterations:\n",
    "\n",
    "            # Compute and Aggregate Gradients\n",
    "            volume_diff.clear()\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                mass_pred = model(images)   \n",
    "                # print(np.shape(mass_pred))\n",
    "                volume = (mass_pred * speeds) * t\n",
    "                # print(volume)\n",
    "                for ixd, vol in enumerate(volume):\n",
    "                    if ixd == 0:\n",
    "                        summed_vol_diff += tf.squared_difference(volume[ixd], init_vol)\n",
    "                        volume_diff.append(tf.squared_difference(volume[ixd], init_vol))\n",
    "                    else:\n",
    "                        summed_vol_diff += tf.squared_difference(volume[ixd], volume[ixd-1])\n",
    "                        volume_diff.append(tf.squared_difference(volume[ixd], volume[ixd-1]))\n",
    "                init_vol = volume[Batch_size-1]\n",
    "                summed_volume += tf.reduce_sum(volume)\n",
    "                watched_vars = tape.watched_variables()\n",
    "            grads = tape.gradient(volume, model.trainable_variables)\n",
    "            grads_diff = tape.gradient(volume_diff, model.trainable_variables)\n",
    "            del tape\n",
    "\n",
    "            if count == 0 and append_flag:\n",
    "                for idx, grad in enumerate(grads):\n",
    "                    aggregated.append(grad)\n",
    "                    aggregated_diff.append(grads_diff[idx])\n",
    "            else:\n",
    "                for idx, grad in enumerate(grads):\n",
    "                    aggregated[idx] = grad+aggregated[idx]\n",
    "                    aggregated_diff[idx] = grads_diff[idx] + aggregated_diff[idx] \n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "            # Compute loss and Apply Gradients\n",
    "            if count == iterations and remainder == 0:\n",
    "                loss = compute_loss(summed_volume, labels[0], log_length[0], operation='Subtraction')\n",
    "                loss_metric = tf.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L2').numpy())\n",
    "                for idx, grd in enumerate(aggregated):\n",
    "                    aggregated[idx] = (loss * 2 * grd) + (summed_vol_diff * 2 * lamda * aggregated_diff[idx] / log_length[0])\n",
    "                rmse = tf.sqrt(tf.abs(loss_metric))\n",
    "                optimizer.apply_gradients(zip(aggregated, model.trainable_variables), global_step=step)\n",
    "                var_list = model.variables\n",
    "                write_summaries(loss_metric, batch, step, var_list[0], grads[0], train=True)\n",
    "                end = time.time() - start\n",
    "                sec = int(end % 60)\n",
    "                mint = int(end/60) % 60\n",
    "                hr = int(end/3600) % 60\n",
    "                # print(volume[0])\n",
    "                print(\"\\r Time_lapsed (hr:mm:ss) --> {:02d}:{:02d}:{:02d} Epoch: {}, Log: {}, Log_progress: {:.1%} - Overall_progress: {:.1%}, Length: {} \"\n",
    "                \"Label:{}, loss: {:.3f}, train RMSE: {:.2f}\".format(hr, mint, sec, epoch+1, cnt_log+1, (cnt_log+1)/logs_N, (epoch+1)/Epochs,  \n",
    "                log_length[0].numpy(), labels[0].numpy(), loss_metric, rmse))\n",
    "\n",
    "                if first_run:\n",
    "                    first_run = False\n",
    "                    loss_ = loss_metric.numpy()\n",
    "\n",
    "                # Reset\n",
    "                aggregated.clear()\n",
    "                aggregated_diff.clear()\n",
    "                summed_vol_diff = 0\n",
    "                init_vol = 0\n",
    "                summed_volume = 0\n",
    "                count = 0\n",
    "                append_flag = True\n",
    "                fixed_size = 0\n",
    "                new_log = True\n",
    "\n",
    "        # Handle the remainder from iterations\n",
    "        else:\n",
    "            # Compute and Aggregate the remainder Gradients\n",
    "            volume_diff.clear()\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                mass_pred = model(images[0:remainder])  \n",
    "                # print(np.shape(mass_pred))\n",
    "                volume = (mass_pred * speeds[0:remainder]) * t\n",
    "                for ixd, vol in enumerate(volume):\n",
    "                    if ixd == 0:\n",
    "                        summed_vol_diff += tf.squared_difference(volume[ixd], init_vol)\n",
    "                        volume_diff.append(tf.squared_difference(volume[ixd], init_vol))\n",
    "                    else:\n",
    "                        summed_vol_diff += tf.squared_difference(volume[ixd], volume[ixd-1])\n",
    "                        volume_diff.append(tf.squared_difference(volume[ixd], volume[ixd-1]))\n",
    "                init_vol = volume[remainder-1]\n",
    "                summed_volume += tf.reduce_sum(volume)\n",
    "                watched_vars = tape.watched_variables()\n",
    "            grads = tape.gradient(volume, model.trainable_variables)\n",
    "            grads_diff = tape.gradient(volume_diff, model.trainable_variables)\n",
    "            del tape\n",
    "\n",
    "            for idx, grad in enumerate(grads):\n",
    "                aggregated[idx] = grad+aggregated[idx]\n",
    "                aggregated_diff[idx] = grads_diff[idx] + aggregated_diff[idx] \n",
    "\n",
    "            # Compute loss and apply gradients for the remainder\n",
    "            loss = compute_loss(summed_volume, labels[0], log_length[0], operation='Subtraction')\n",
    "            loss_metric = tf.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L2').numpy())\n",
    "            for idx, grd in enumerate(aggregated):\n",
    "                aggregated[idx] = (loss * 2 * grd) + (summed_vol_diff * 2 * lamda * aggregated_diff[idx] / log_length[0])\n",
    "            rmse = tf.squeeze(tf.sqrt(tf.abs(loss_metric)))\n",
    "            optimizer.apply_gradients(zip(aggregated, model.trainable_variables), global_step=step)\n",
    "            var_list = model.trainable_variables\n",
    "            write_summaries(loss_metric, batch, step, var_list[0], grads[0], train=True)\n",
    "            end = time.time() - start\n",
    "            sec = int(end % 60)\n",
    "            mint = int(end/60) % 60\n",
    "            hr = int(end/3600) % 60\n",
    "            # print(volume[0])\n",
    "            print(\"\\r Time_lapsed (hr:mm:ss) --> {:02d}:{:02d}:{:02d} Epoch: {}, Log: {}, Log_progress: {:.1%} - Overall_progress: {:.1%}, Length: {} \"\n",
    "                  \"Label:{}, loss: {:.3f}, train RMSE: {:.2f}\".format(hr, mint, sec, epoch+1, cnt_log+1, (cnt_log+1)/logs_N, (epoch+1)/Epochs,  \n",
    "                  log_length[0].numpy(), labels[0].numpy(), loss_metric, rmse))\n",
    "\n",
    "            if first_run:\n",
    "                first_run = False\n",
    "                loss_ = loss_metric.numpy()\n",
    "\n",
    "            # Reset\n",
    "            aggregated.clear()\n",
    "            aggregated_diff.clear()\n",
    "            summed_vol_diff = 0\n",
    "            init_vol = 0\n",
    "            summed_volume = 0\n",
    "            count = 0\n",
    "            append_flag = True\n",
    "            new_log = True\n",
    "\n",
    "            # Handle gradients for the next log\n",
    "            if cnt_log != logs_N-1:\n",
    "                # Compute and Aggregate Gradients\n",
    "                volume_diff.clear()\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    mass_pred = model(images[remainder:])\n",
    "                    # print(np.shape(mass_pred))\n",
    "                    volume = (mass_pred * speeds[remainder:]) * t\n",
    "                    for ixd, vol in enumerate(volume):\n",
    "                        if ixd == 0:\n",
    "                            summed_vol_diff += tf.squared_difference(volume[ixd], init_vol)\n",
    "                            volume_diff.append(tf.squared_difference(volume[ixd], init_vol))\n",
    "                        else:\n",
    "                            summed_vol_diff += tf.squared_difference(volume[ixd], volume[ixd-1])\n",
    "                            volume_diff.append(tf.squared_difference(volume[ixd], volume[ixd-1]))\n",
    "                    init_vol = volume[Batch_size-remainder-1]\n",
    "\n",
    "                    summed_volume += tf.reduce_sum(volume)\n",
    "                    watched_vars = tape.watched_variables()\n",
    "                grads = tape.gradient(volume, model.trainable_variables)\n",
    "                grads_diff = tape.gradient(volume_diff, model.trainable_variables)\n",
    "                del tape\n",
    "\n",
    "                for idx, grad in enumerate(grads):\n",
    "                    aggregated.append(grad)\n",
    "                    aggregated_diff.append(grads_diff[idx])\n",
    "                append_flag = False\n",
    "    # Validate model every epoch to determine early stopping\n",
    "    MSE_log, MAE_log, MSBE_log, accuracy_, val_step = validate_model(model, val_step, 1, sample_dataset, write_summary=True,\n",
    "                                                                     return_losses=True)\n",
    "    print('\\n')\n",
    "    MSE_t.append(MSE_log)   # contains log losses for each epoch\n",
    "    MAE_t.append(MAE_log)\n",
    "    MSBE_t.append(MSBE_log)\n",
    "    MSE_avg.append(np.mean(MSE_log))    # contains average log losses for each epoch\n",
    "    MAE_avg.append(np.mean(MAE_log))\n",
    "    MSBE_avg.append(np.mean(MSBE_log))\n",
    "    MSE_train.append(loss_metric)\n",
    "    error = 1 - np.mean(accuracy_)\n",
    "    full_data_dict= {\"MSE_t\": MSE_t, \"MAE_t\": MAE_t, \"MSBE_t\": MSBE_t, \"MSE_avg\": MSE_avg, \"MAE_avg\": MAE_avg, \"MSBE_avg\": MSBE_avg, \"MSE_train\": MSE_train}\n",
    "    pickle_out = open(MAIN_dir+\"data_files/\"+\"losses_\"+run_name+\".pickle\", \"wb\")\n",
    "    pk.dump(full_data_dict, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    # save model weights every epoch after 50 epochs lapsed\n",
    "    if performance_flag:\n",
    "        if error <= 0.06:\n",
    "            model.save_weights(checkpont_path.format(log=epoch))  \n",
    "    else:\n",
    "        if epoch >= save_epoch:\n",
    "            model.save_weights(checkpont_path.format(log=epoch))\n",
    "\n",
    "    if error <= 0.02:\n",
    "        epoch = 1000   # end training\n",
    "        break\n",
    "\n",
    "model.save_weights(checkpoint_path + 'cp-'+run_name+'.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\r Validation_Time (hr:mm:ss) --> 00:00:00 ,   Avg_loss: 0.3408467   Avg_accuracy: 97.9%   Overall Progress:100.0%, completed 1 out of 1 logs\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "signals = validate_model(model, 1, 1, sample_dataset, write_summary=False, return_losses=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|██████████| 1/1 [00:00<00:00, 15.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "signal = []\n",
    "signalz = []\n",
    "onehot_signals = []\n",
    "speed_signal = []\n",
    "cnt = 0\n",
    "target_name = 'sample_signal.npy'\n",
    "for sig in tqdm(signals):\n",
    "    for si in sig:\n",
    "        for s in si:\n",
    "            sm = np.float32(np.squeeze(s.numpy()))\n",
    "            signal.append(sm)\n",
    "            speed_signal.append(speeds[cnt])\n",
    "            onehot_signals.append(sm)\n",
    "            cnt += 1\n",
    "    signalz.append([labels[cnt-1], log_length[cnt-1], signal[:len(signal)], \n",
    "                    speed_signal[:len(speed_signal)]])\n",
    "    signal.clear()\n",
    "    speed_signal.clear()\n",
    "\n",
    "\n",
    "np.save(data_files_path+target_name, signalz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth:290.29888 Prediction:296.2851371645508 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal = signalz[0][2]\n",
    "lb2kg = 0.453592\n",
    "gt = np.squeeze(signalz[0][0]) * lb2kg\n",
    "prd = np.sum(signalz[0][2]) * lb2kg\n",
    "plt.plot(signalz[0][2], '--')\n",
    "print('Ground Truth:{0:} Prediction:{1:} '.format(gt, prd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
