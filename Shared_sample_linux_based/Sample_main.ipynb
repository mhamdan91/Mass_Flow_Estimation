{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "from tqdm import tqdm    \n",
    "\n",
    "from termcolor import colored\n",
    "import tensorflow as tf\n",
    "import os                   # work with directories\n",
    "import numpy as np          # dealing with arrays\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tfe = tf.contrib.eager\n",
    "import pickle as pk\n",
    "import sys\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.python.eager import tape\n",
    "import platform\n",
    "machine_type = platform.uname()[0]\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "layers = tf.keras.layers\n",
    "tf.enable_eager_execution(config=config)\n",
    "tf.executing_eagerly()\n",
    "print(tf.__version__)\n",
    "\n",
    "if machine_type == 'Linux':\n",
    "    path_sep = '/'\n",
    "else:\n",
    "    path_sep = '\\win'\n",
    "HOME_DIR = os.getcwd()\n",
    "MAIN_dir = HOME_DIR + path_sep+'Cleaned_code'+path_sep+'Shared_git'+path_sep\n",
    "checkpoint_path = MAIN_dir + 'checkpoints'+path_sep\n",
    "data_files_path = MAIN_dir + 'data_files'+path_sep\n",
    "mean_path = data_files_path + 'std_mean_60_dataset.npy'\n",
    "dataset_path = MAIN_dir + 'dataset'+path_sep\n",
    "tensorboard_path = MAIN_dir + 'tensorboard'+path_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'sample_set.pickle'\n",
    "pickle_in_sample = open(MAIN_dir + 'data_files/' + filename, \"rb\")\n",
    "sample_data = pk.load(pickle_in_sample)\n",
    "pickle_in_sample.close()\n",
    "\n",
    "images_s = sample_data['images']\n",
    "labels_s = sample_data['labels']\n",
    "speeds_s = sample_data['speeds']\n",
    "log_length_s = sample_data['log_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample og length is 511 , so make sure batch_size is less or equal to that and whatever you can fit in vRAM\n",
    "Batch_size = 8\n",
    "Buffer_size = 8\n",
    "Epochs = 100\n",
    "\n",
    "sample_dataset = tf.data.Dataset.from_tensor_slices((images_s, labels_s, speeds_s, log_length_s))\n",
    "sample_dataset = sample_dataset.batch(Batch_size)\n",
    "sample_dataset = sample_dataset.prefetch(Batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RES-9ER - default --- for deployment change to current working directory\n",
    "\n",
    "Network_size = None # Set to default RES-9ER\n",
    "data_format = 'channels_last'\n",
    "if Network_size == 16:\n",
    "    from Cleaned_code.Shared_git.models import RES_16E as Res\n",
    "elif Network_size == 9:\n",
    "    from Cleaned_code.Shared_git.models import RES_9E as Res\n",
    "else:\n",
    "    from Cleaned_code.Shared_git.models import RES_9ER as Res\n",
    "    \n",
    "    \n",
    "# Instantiate the model and configure tensorbaord and checkpoints\n",
    "\n",
    "model = Res.Res9ER(data_format=data_format, include_top=True, pooling=None, classes=1)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "accuracy = 0 \n",
    "acc_prediction = tf.constant(0, dtype=\"float32\")\n",
    "t = tf.constant(1/7.5, dtype=\"float32\")\n",
    "loss = tf.constant(0, dtype=\"float32\")\n",
    "logdir = tensorboard_path\n",
    "loc_checkpoint_path = checkpoint_path+'generated_checkpoints/'+\"cp-{log:06d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(loc_checkpoint_path)\n",
    "summary_writer = tf.contrib.summary.create_file_writer(logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7ff84ca5ec50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD checkpoint if you wish to test results\n",
    "checkpoint_name = 'RES_9ER'\n",
    "model.load_weights(checkpoint_path+checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(prediction, label, train_log_length_, operation='L2'):\n",
    "    if operation == 'L2':\n",
    "        return tf.divide(tf.squared_difference(prediction, label), train_log_length_)\n",
    "    elif operation == 'Subtraction':\n",
    "        return tf.divide(tf.subtract(prediction, label), train_log_length_)\n",
    "    elif operation == 'L1':\n",
    "        return tf.divide(tf.abs(tf.subtract(prediction, label)), train_log_length_)\n",
    "    else:\n",
    "        raise ValueError('Please specify loss function (L2, L1, Subtraction)')\n",
    "\n",
    "\n",
    "def print_progress(count, total, cnt, overall, time_, count_log, loss, loss_):\n",
    "    percent_complete = float(count) / total\n",
    "    overall_complete = float(cnt) / (overall-1)\n",
    "\n",
    "    sec = time_ % 60\n",
    "    mint = int(time_/60) % 60\n",
    "    hr = int(time_/3600) % 60\n",
    "    loss = str(loss)\n",
    "    loss_ = str(loss_)\n",
    "    msg = \"\\r Time_lapsed (hr:mm:ss) --> {0:02d}:{1:02d}:{2:02d} ,   loss: {3:s}   Log Progress: {4:.1%},     Overall Progress:{5:.1%},\" \\\n",
    "        \" completed {6:d} out of 185 logs <--> Initial loss: {7:s} \".format(hr, mint, sec, loss, percent_complete, overall_complete, count_log, loss_)\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "\n",
    "def validation_progress(log_cnt, num_logs, time_, loss, accuracy_loc):\n",
    "    log_cnt += 1\n",
    "    overall_complete = float(log_cnt) / num_logs\n",
    "    sec = int(time_) % 60\n",
    "    mint = int(time_/60) % 60\n",
    "    hr = int(time_/3600) % 60\n",
    "    loss = str(loss)\n",
    "    msg = \"\\r Validation_Time (hr:mm:ss) --> {0:02d}:{1:02d}:{2:02d} ,   Avg_loss: {3:s}   Avg_accuracy: {4:.2%}   Overall Progress:{5:.1%},\" \\\n",
    "        \" completed {6:d} out of {7:d} logs\".format(hr, mint, sec, loss, accuracy_loc, overall_complete, log_cnt, num_logs)\n",
    "    sys.stdout.write(colored(msg, 'green'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def write_summaries(loss, i, global_step, vars_loc, grads_loc, train=True):\n",
    "    with summary_writer.as_default():\n",
    "        with tf.contrib.summary.always_record_summaries():\n",
    "            if train:\n",
    "                tf.contrib.summary.scalar(\"train_loss\", loss, step=global_step)\n",
    "                tf.contrib.summary.scalar(\"step\", i, step=global_step)\n",
    "                #  do not add spaces after names\n",
    "                tf.contrib.summary.histogram(\"weights\", vars_loc, step=global_step)\n",
    "                tf.contrib.summary.histogram(\"gradients\", grads_loc, step=global_step)\n",
    "            else:\n",
    "                tf.contrib.summary.scalar(\"val_loss\", loss, step=global_step)\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION CODE\n",
    "\n",
    "def validate_model(model_loc, val_step_, n_logs, data_set, write_summary=True, return_losses=True):\n",
    "    logs_N = n_logs\n",
    "    start = time.time()\n",
    "    MAE = []\n",
    "    MSE = []\n",
    "    MSBE = []\n",
    "    log_order = []\n",
    "    Accuracy = []\n",
    "    metric_mse = []\n",
    "    summed_volume = 0\n",
    "    remainder = 0\n",
    "    iterations = 0\n",
    "    fixed_size = 0\n",
    "    count = 0\n",
    "    new_log = True\n",
    "    cnt_log = -1\n",
    "    signal = []\n",
    "    signals = [] \n",
    "    for (batch, (image, label, speed, lengths)) in (enumerate(data_set)):\n",
    "        size = np.shape(label)[0]\n",
    "        labels = tf.reshape(label, [size, 1])\n",
    "        speeds = tf.reshape(speed, [size, 1])\n",
    "        log_length = tf.squeeze(lengths)\n",
    "        images = tf.squeeze(image)\n",
    "        batch += 1\n",
    "        if new_log:           \n",
    "            new_log = False\n",
    "            length = int(log_length[0].numpy() - fixed_size + remainder)\n",
    "            iterations = int(np.floor(length/Batch_size))\n",
    "            remainder = int(np.mod(length, Batch_size))\n",
    "            fixed_size = np.shape(speeds)[0]\n",
    "            cnt_log += 1\n",
    "\n",
    "        if count < iterations:\n",
    "            mass_pred = model_loc(images)\n",
    "            volume = (mass_pred * speeds) * t\n",
    "            summed_volume += tf.reduce_sum(volume)\n",
    "            mass = np.abs(summed_volume.numpy())\n",
    "            count = count + 1\n",
    "            signal.append(volume)\n",
    "            # Compute loss\n",
    "            if count == iterations and remainder == 0:\n",
    "                loss_unsigned = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L2').numpy())\n",
    "                loss_outlier = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L1').numpy())\n",
    "                loss_signed = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='Subtraction').numpy())\n",
    "                MSE.append(loss_unsigned)\n",
    "                MAE.append(loss_outlier)\n",
    "                MSBE.append(loss_signed)\n",
    "                signals.append(signal[0:len(signal)])\n",
    "                signal.clear()\n",
    "        \n",
    "                gt = np.squeeze(labels[0].numpy())\n",
    "                metric_mse.append(loss_unsigned)\n",
    "                \n",
    "                tmp = np.abs(gt - mass)\n",
    "                tmp = tmp / gt\n",
    "                log_acc = 1 - np.squeeze(tmp)\n",
    "                    \n",
    "                Accuracy.append(log_acc)\n",
    "                log_order.append(np.squeeze(log_length[0].numpy()))\n",
    "                time_ = time.time() - start\n",
    "                validation_progress(cnt_log, logs_N, time_, np.mean(metric_mse), np.mean(Accuracy))\n",
    "                if write_summary:\n",
    "                    write_summaries(np.mean(MSE), 0, val_step_, 0, 0, train=False)\n",
    "                val_step_ += 1\n",
    "                # Reset\n",
    "                summed_volume = 0\n",
    "                count = 0\n",
    "                fixed_size = 0\n",
    "                new_log = True\n",
    "        # Handle the remainder from iterations\n",
    "        else:\n",
    "            # Compute and Aggregate the remainder Gradients\n",
    "            mass_pred = model(images[0:remainder])\n",
    "            volume = (mass_pred * speeds[0:remainder]) * t\n",
    "            summed_volume += tf.reduce_sum(volume)\n",
    "            mass = np.abs(summed_volume.numpy())\n",
    "            signal.append(volume)\n",
    "            \n",
    "            loss_unsigned = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L2').numpy())\n",
    "            loss_outlier = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L1').numpy())\n",
    "            loss_signed = np.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='Subtraction').numpy())\n",
    "            MSE.append(loss_unsigned)\n",
    "            MAE.append(loss_outlier)\n",
    "            MSBE.append(loss_signed)\n",
    "            signals.append(signal[0:len(signal)])\n",
    "            signal.clear()\n",
    "            \n",
    "            gt = np.squeeze(labels[0].numpy())\n",
    "            metric_mse.append(loss_unsigned)\n",
    "\n",
    "            tmp = np.abs(gt - mass)\n",
    "            tmp = tmp / gt\n",
    "            log_acc = 1 - np.squeeze(tmp)\n",
    "            \n",
    "            Accuracy.append(log_acc)\n",
    "            log_order.append(np.squeeze(log_length[0].numpy()))\n",
    "            time_ = time.time() - start\n",
    "            validation_progress(cnt_log, logs_N, time_, np.mean(metric_mse), np.mean(Accuracy))  \n",
    "            \n",
    "            if write_summary:  \n",
    "                write_summaries(np.mean(MSE), 0, val_step_, 0, 0, train=False)\n",
    "            val_step_ += 1\n",
    "            summed_volume = 0\n",
    "            count = 0\n",
    "            new_log = True\n",
    "            \n",
    "            # Handle gradients for the next log\n",
    "            if cnt_log != logs_N-1:    \n",
    "                mass_pred = model(images[remainder:])\n",
    "                volume = (mass_pred * speeds[remainder:]) * t\n",
    "                summed_volume += tf.reduce_sum(volume)\n",
    "                signal.append(volume)\n",
    "                \n",
    "    if return_losses:\n",
    "        return MSE, MAE, MSBE, Accuracy, val_step_\n",
    "    else: \n",
    "        return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r Time_lapsed (hr:mm:ss) --> 00:00:01 Epoch: 1, Log: 1, Log_progress: 100.0% - Overall_progress: 1.0%, Length: 511.0 Label:[640.], loss: 0.341, train RMSE: 0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\r Validation_Time (hr:mm:ss) --> 00:00:00 ,   Avg_loss: 0.75073516   Avg_accuracy: 96.94%   Overall Progress:100.0%, completed 1 out of 1 logs\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r Time_lapsed (hr:mm:ss) --> 00:00:02 Epoch: 2, Log: 1, Log_progress: 100.0% - Overall_progress: 2.0%, Length: 511.0 Label:[640.], loss: 0.751, train RMSE: 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\r Validation_Time (hr:mm:ss) --> 00:00:00 ,   Avg_loss: 0.38081747   Avg_accuracy: 97.82%   Overall Progress:100.0%, completed 1 out of 1 logs\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r Time_lapsed (hr:mm:ss) --> 00:00:04 Epoch: 3, Log: 1, Log_progress: 100.0% - Overall_progress: 3.0%, Length: 511.0 Label:[640.], loss: 0.381, train RMSE: 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\r Validation_Time (hr:mm:ss) --> 00:00:00 ,   Avg_loss: 3.3448618e-05   Avg_accuracy: 99.98%   Overall Progress:100.0%, completed 1 out of 1 logs\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n"
     ]
    }
   ],
   "source": [
    "# TRAINING CODE  -- or move the following cell if you just wish to test results and make plots \n",
    "save_epoch = 1\n",
    "init_vol = 0\n",
    "summed_vol_diff = 0\n",
    "volume_diff = []\n",
    "aggregated_diff = []\n",
    "lamda = 0.05\n",
    "loss_ = 0\n",
    "logs_N = 1\n",
    "start = time.time()\n",
    "aggregated = []\n",
    "MSE_log = []\n",
    "MAE_log = []\n",
    "MSBE_log = []\n",
    "MSE_t = []\n",
    "MAE_t = []\n",
    "MSBE_t = []\n",
    "MSE_avg = []\n",
    "MAE_avg = []\n",
    "MSBE_avg = []\n",
    "MSE_train = []\n",
    "val_step = 1\n",
    "run_name = 'random'\n",
    "performance_flag = True\n",
    "for epoch in range(Epochs):\n",
    "    loss_metric = 0\n",
    "    summed_volume = 0\n",
    "    remainder = 0\n",
    "    iterations = 0\n",
    "    fixed_size = 0\n",
    "    count = 0\n",
    "    new_log = True\n",
    "    append_flag = True\n",
    "    next_log = False\n",
    "    cnt_log = -1\n",
    "    first_run = True    \n",
    "    for (batch, (image, label, speed, lengths)) in (enumerate(sample_dataset)):\n",
    "        size = np.shape(label)[0]\n",
    "        labels = tf.reshape(label, [size, 1])\n",
    "        speeds = tf.reshape(speed, [size, 1])\n",
    "        log_length = tf.squeeze(lengths)\n",
    "        images = tf.squeeze(image)\n",
    "        batch += 1\n",
    "        step = tf.train.get_or_create_global_step()\n",
    "        if new_log:           \n",
    "            new_log = False\n",
    "            length = int(log_length[0].numpy() - fixed_size + remainder)\n",
    "            iterations = int(np.floor(length/Batch_size))\n",
    "            remainder = int(np.mod(length, Batch_size))\n",
    "            fixed_size = np.shape(speeds)[0]\n",
    "            cnt_log += 1\n",
    "\n",
    "        if count < iterations:\n",
    "\n",
    "            # Compute and Aggregate Gradients\n",
    "            volume_diff.clear()\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                mass_pred = model(images)   \n",
    "                # print(np.shape(mass_pred))\n",
    "                volume = (mass_pred * speeds) * t\n",
    "                # print(volume)\n",
    "                for ixd, vol in enumerate(volume):\n",
    "                    if ixd == 0:\n",
    "                        summed_vol_diff += tf.squared_difference(volume[ixd], init_vol)\n",
    "                        volume_diff.append(tf.squared_difference(volume[ixd], init_vol))\n",
    "                    else:\n",
    "                        summed_vol_diff += tf.squared_difference(volume[ixd], volume[ixd-1])\n",
    "                        volume_diff.append(tf.squared_difference(volume[ixd], volume[ixd-1]))\n",
    "                init_vol = volume[Batch_size-1]\n",
    "                summed_volume += tf.reduce_sum(volume)\n",
    "                watched_vars = tape.watched_variables()\n",
    "            grads = tape.gradient(volume, model.trainable_variables)\n",
    "            grads_diff = tape.gradient(volume_diff, model.trainable_variables)\n",
    "            del tape\n",
    "\n",
    "            if count == 0 and append_flag:\n",
    "                for idx, grad in enumerate(grads):\n",
    "                    aggregated.append(grad)\n",
    "                    aggregated_diff.append(grads_diff[idx])\n",
    "            else:\n",
    "                for idx, grad in enumerate(grads):\n",
    "                    aggregated[idx] = grad+aggregated[idx]\n",
    "                    aggregated_diff[idx] = grads_diff[idx] + aggregated_diff[idx] \n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "            # Compute loss and Apply Gradients\n",
    "            if count == iterations and remainder == 0:\n",
    "                loss = compute_loss(summed_volume, labels[0], log_length[0], operation='Subtraction')\n",
    "                loss_metric = tf.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L2').numpy())\n",
    "                for idx, grd in enumerate(aggregated):\n",
    "                    aggregated[idx] = (loss * 2 * grd) + (summed_vol_diff * 2 * lamda * aggregated_diff[idx] / log_length[0])\n",
    "                rmse = tf.sqrt(tf.abs(loss_metric))\n",
    "                optimizer.apply_gradients(zip(aggregated, model.trainable_variables), global_step=step)\n",
    "                var_list = model.variables\n",
    "                write_summaries(loss_metric, batch, step, var_list[0], grads[0], train=True)\n",
    "                end = time.time() - start\n",
    "                sec = int(end % 60)\n",
    "                mint = int(end/60) % 60\n",
    "                hr = int(end/3600) % 60\n",
    "                # print(volume[0])\n",
    "                print(\"\\r Time_lapsed (hr:mm:ss) --> {:02d}:{:02d}:{:02d} Epoch: {}, Log: {}, Log_progress: {:.1%} - Overall_progress: {:.1%}, Length: {} \"\n",
    "                \"Label:{}, loss: {:.3f}, train RMSE: {:.2f}\".format(hr, mint, sec, epoch+1, cnt_log+1, (cnt_log+1)/logs_N, (epoch+1)/Epochs,  \n",
    "                log_length[0].numpy(), labels[0].numpy(), loss_metric, rmse))\n",
    "\n",
    "                if first_run:\n",
    "                    first_run = False\n",
    "                    loss_ = loss_metric.numpy()\n",
    "\n",
    "                # Reset\n",
    "                aggregated.clear()\n",
    "                aggregated_diff.clear()\n",
    "                summed_vol_diff = 0\n",
    "                init_vol = 0\n",
    "                summed_volume = 0\n",
    "                count = 0\n",
    "                append_flag = True\n",
    "                fixed_size = 0\n",
    "                new_log = True\n",
    "\n",
    "        # Handle the remainder from iterations\n",
    "        else:\n",
    "            # Compute and Aggregate the remainder Gradients\n",
    "            volume_diff.clear()\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                mass_pred = model(images[0:remainder])  \n",
    "                # print(np.shape(mass_pred))\n",
    "                volume = (mass_pred * speeds[0:remainder]) * t\n",
    "                for ixd, vol in enumerate(volume):\n",
    "                    if ixd == 0:\n",
    "                        summed_vol_diff += tf.squared_difference(volume[ixd], init_vol)\n",
    "                        volume_diff.append(tf.squared_difference(volume[ixd], init_vol))\n",
    "                    else:\n",
    "                        summed_vol_diff += tf.squared_difference(volume[ixd], volume[ixd-1])\n",
    "                        volume_diff.append(tf.squared_difference(volume[ixd], volume[ixd-1]))\n",
    "                init_vol = volume[remainder-1]\n",
    "                summed_volume += tf.reduce_sum(volume)\n",
    "                watched_vars = tape.watched_variables()\n",
    "            grads = tape.gradient(volume, model.trainable_variables)\n",
    "            grads_diff = tape.gradient(volume_diff, model.trainable_variables)\n",
    "            del tape\n",
    "\n",
    "            for idx, grad in enumerate(grads):\n",
    "                aggregated[idx] = grad+aggregated[idx]\n",
    "                aggregated_diff[idx] = grads_diff[idx] + aggregated_diff[idx] \n",
    "\n",
    "            # Compute loss and apply gradients for the remainder\n",
    "            loss = compute_loss(summed_volume, labels[0], log_length[0], operation='Subtraction')\n",
    "            loss_metric = tf.squeeze(compute_loss(summed_volume, labels[0], log_length[0], operation='L2').numpy())\n",
    "            for idx, grd in enumerate(aggregated):\n",
    "                aggregated[idx] = (loss * 2 * grd) + (summed_vol_diff * 2 * lamda * aggregated_diff[idx] / log_length[0])\n",
    "            rmse = tf.squeeze(tf.sqrt(tf.abs(loss_metric)))\n",
    "            optimizer.apply_gradients(zip(aggregated, model.trainable_variables), global_step=step)\n",
    "            var_list = model.trainable_variables\n",
    "            write_summaries(loss_metric, batch, step, var_list[0], grads[0], train=True)\n",
    "            end = time.time() - start\n",
    "            sec = int(end % 60)\n",
    "            mint = int(end/60) % 60\n",
    "            hr = int(end/3600) % 60\n",
    "            # print(volume[0])\n",
    "            print(\"\\r Time_lapsed (hr:mm:ss) --> {:02d}:{:02d}:{:02d} Epoch: {}, Log: {}, Log_progress: {:.1%} - Overall_progress: {:.1%}, Length: {} \"\n",
    "                  \"Label:{}, loss: {:.3f}, train RMSE: {:.2f}\".format(hr, mint, sec, epoch+1, cnt_log+1, (cnt_log+1)/logs_N, (epoch+1)/Epochs,  \n",
    "                  log_length[0].numpy(), labels[0].numpy(), loss_metric, rmse))\n",
    "\n",
    "            if first_run:\n",
    "                first_run = False\n",
    "                loss_ = loss_metric.numpy()\n",
    "\n",
    "            # Reset\n",
    "            aggregated.clear()\n",
    "            aggregated_diff.clear()\n",
    "            summed_vol_diff = 0\n",
    "            init_vol = 0\n",
    "            summed_volume = 0\n",
    "            count = 0\n",
    "            append_flag = True\n",
    "            new_log = True\n",
    "\n",
    "            # Handle gradients for the next log\n",
    "            if cnt_log != logs_N-1:\n",
    "                # Compute and Aggregate Gradients\n",
    "                volume_diff.clear()\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    mass_pred = model(images[remainder:])\n",
    "                    # print(np.shape(mass_pred))\n",
    "                    volume = (mass_pred * speeds[remainder:]) * t\n",
    "                    for ixd, vol in enumerate(volume):\n",
    "                        if ixd == 0:\n",
    "                            summed_vol_diff += tf.squared_difference(volume[ixd], init_vol)\n",
    "                            volume_diff.append(tf.squared_difference(volume[ixd], init_vol))\n",
    "                        else:\n",
    "                            summed_vol_diff += tf.squared_difference(volume[ixd], volume[ixd-1])\n",
    "                            volume_diff.append(tf.squared_difference(volume[ixd], volume[ixd-1]))\n",
    "                    init_vol = volume[Batch_size-remainder-1]\n",
    "\n",
    "                    summed_volume += tf.reduce_sum(volume)\n",
    "                    watched_vars = tape.watched_variables()\n",
    "                grads = tape.gradient(volume, model.trainable_variables)\n",
    "                grads_diff = tape.gradient(volume_diff, model.trainable_variables)\n",
    "                del tape\n",
    "\n",
    "                for idx, grad in enumerate(grads):\n",
    "                    aggregated.append(grad)\n",
    "                    aggregated_diff.append(grads_diff[idx])\n",
    "                append_flag = False\n",
    "    # Validate model every epoch to determine early stopping -- not necessary in this single log case\n",
    "    MSE_log, MAE_log, MSBE_log, accuracy_, val_step = validate_model(model, val_step, 1, sample_dataset, write_summary=True,\n",
    "                                                                     return_losses=True)\n",
    "    print('\\n')\n",
    "    MSE_t.append(MSE_log)   # contains log losses for each epoch\n",
    "    MAE_t.append(MAE_log)\n",
    "    MSBE_t.append(MSBE_log)\n",
    "    MSE_avg.append(np.mean(MSE_log))    # contains average log losses for each epoch\n",
    "    MAE_avg.append(np.mean(MAE_log))\n",
    "    MSBE_avg.append(np.mean(MSBE_log))\n",
    "    MSE_train.append(loss_metric)\n",
    "    error = 1 - np.mean(accuracy_)\n",
    "    full_data_dict= {\"MSE_t\": MSE_t, \"MAE_t\": MAE_t, \"MSBE_t\": MSBE_t, \"MSE_avg\": MSE_avg, \"MAE_avg\": MAE_avg, \"MSBE_avg\": MSBE_avg, \"MSE_train\": MSE_train}\n",
    "    pickle_out = open(MAIN_dir+\"data_files/\"+\"losses_\"+run_name+\".pickle\", \"wb\")\n",
    "    pk.dump(full_data_dict, pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    # save model weights when performance flag for 94% and above\n",
    "    if performance_flag:\n",
    "        if error <= 0.06:\n",
    "            model.save_weights(loc_checkpoint_path.format(log=epoch))  \n",
    "    else:\n",
    "        if epoch >= save_epoch:\n",
    "            model.save_weights(loc_checkpoint_path.format(log=epoch))\n",
    "\n",
    "    if error <= 0.005:   # end training for 99.5% -- change this for higher or lower accuracy termination\n",
    "        break\n",
    "\n",
    "model.save_weights(checkpoint_dir + '/cp-'+run_name+'.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\r Validation_Time (hr:mm:ss) --> 00:00:00 ,   Avg_loss: 3.3448618e-05   Avg_accuracy: 99.98%   Overall Progress:100.0%, completed 1 out of 1 logs\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Obtain a signal \n",
    "signals = validate_model(model, 1, 1, sample_dataset, write_summary=False, return_losses=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate predicted signal with proper information and save it\n",
    "signal = []\n",
    "signalz = []\n",
    "onehot_signals = []\n",
    "speed_signal = []\n",
    "cnt = 0\n",
    "target_name = 'sample_signal.npy'\n",
    "for sig in tqdm(signals):\n",
    "    for si in sig:\n",
    "        for s in si:\n",
    "            sm = np.float32(np.squeeze(s.numpy()))\n",
    "            signal.append(sm)\n",
    "            speed_signal.append(speeds_s[cnt])\n",
    "            onehot_signals.append(sm)\n",
    "            cnt += 1\n",
    "    signalz.append([labels_s[cnt-1], log_length_s[cnt-1], signal[:len(signal)], \n",
    "                    speed_signal[:len(speed_signal)]])\n",
    "    signal.clear()\n",
    "    speed_signal.clear()\n",
    "\n",
    "\n",
    "np.save(data_files_path+target_name, signalz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth:290.29888 Prediction:290.2395509194336  Accuracy:99.98% \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Predicted signal\n",
    "\n",
    "signal = signalz[0][2]\n",
    "lb2kg = 0.453592\n",
    "gt = np.squeeze(signalz[0][0]) * lb2kg\n",
    "prd = np.sum(signalz[0][2]) * lb2kg\n",
    "plt.plot(signalz[0][2], '--')\n",
    "ACC = (1-np.abs(gt-prd)/gt)\n",
    "print('Ground Truth:{0:} Prediction:{1:}  Accuracy:{2:.2%} '.format(gt, prd, ACC))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
