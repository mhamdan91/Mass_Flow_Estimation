{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Grad cam code\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "from tqdm import tqdm    \n",
    "\n",
    "from termcolor import colored\n",
    "import tensorflow as tf\n",
    "import os                   # work with directories\n",
    "import numpy as np          # dealing with arrays\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tfe = tf.contrib.eager\n",
    "import pickle as pk\n",
    "import sys\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.python.eager import tape\n",
    "import  cv2\n",
    "import platform\n",
    "\n",
    "from skimage.transform import resize\n",
    "import warnings\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "layers = tf.keras.layers\n",
    "tf.enable_eager_execution(config=config)\n",
    "tf.executing_eagerly()\n",
    "print(tf.__version__)\n",
    "\n",
    "machine_type = platform.uname()[0]\n",
    "if machine_type == 'Linux':\n",
    "    path_sep = '/'\n",
    "else:\n",
    "    path_sep = '\\win'\n",
    "HOME_DIR = os.getcwd()\n",
    "MAIN_dir = HOME_DIR + path_sep+'Cleaned_code'+path_sep+'Shared_git'+path_sep\n",
    "checkpoint_path = MAIN_dir + path_sep+'utils'+path_sep+'checkpoints'+path_sep\n",
    "data_files_path = MAIN_dir + 'data_files'+path_sep\n",
    "mean_path = data_files_path + 'std_mean_60_dataset.npy'\n",
    "dataset_path = MAIN_dir + 'dataset'+path_sep\n",
    "output_path = MAIN_dir+'utils'+ path_sep+'output'+ path_sep+'gracam.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'sample_set.pickle'\n",
    "pickle_in_sample = open(MAIN_dir + 'data_files/' + filename, \"rb\")\n",
    "sample_data = pk.load(pickle_in_sample)\n",
    "pickle_in_sample.close()\n",
    "\n",
    "images_s = sample_data['images']\n",
    "labels_s = sample_data['labels']\n",
    "speeds_s = sample_data['speeds']\n",
    "log_length_s = sample_data['log_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 1\n",
    "Buffer_size = 1\n",
    "Epochs = 100\n",
    "\n",
    "sample_dataset = tf.data.Dataset.from_tensor_slices((images_s, labels_s, speeds_s, log_length_s))\n",
    "sample_dataset = sample_dataset.batch(Batch_size)\n",
    "sample_dataset = sample_dataset.prefetch(Batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RES-9ER - default\n",
    "from Cleaned_code.Shared_git.utils.models import RES_9ER_CAM as Res\n",
    "\n",
    "# Instantiate the model and configure tensorbaord and checkpoints\n",
    "data_format = 'channels_last'\n",
    "model = Res.Res9ER(data_format=data_format, include_top=True, pooling=None, classes=1)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "accuracy = 0 \n",
    "acc_prediction = tf.constant(0, dtype=\"float32\")\n",
    "t = tf.constant(1/7.5, dtype=\"float32\")\n",
    "loss = tf.constant(0, dtype=\"float32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7fddc40ca1d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD checkpoint if you wish to test results\n",
    "checkpoint_name = 'Gradcam_RES_9ER'\n",
    "model.load_weights(checkpoint_path+checkpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(prediction, label, train_log_length_, operation='L2'):\n",
    "    if operation == 'L2':\n",
    "        return tf.divide(tf.squared_difference(prediction, label), train_log_length_)\n",
    "    elif operation == 'Subtraction':\n",
    "        return tf.divide(tf.subtract(prediction, label), train_log_length_)\n",
    "    elif operation == 'L1':\n",
    "        return tf.divide(tf.abs(tf.subtract(prediction, label)), train_log_length_)\n",
    "    else:\n",
    "        raise ValueError('Please specify loss function (L2, L1, Subtraction)')\n",
    "\n",
    "\n",
    "def print_progress(count, total, cnt, overall, time_, count_log, loss, loss_):\n",
    "    percent_complete = float(count) / total\n",
    "    overall_complete = float(cnt) / (overall-1)\n",
    "\n",
    "    sec = time_ % 60\n",
    "    mint = int(time_/60) % 60\n",
    "    hr = int(time_/3600) % 60\n",
    "    loss = str(loss)\n",
    "    loss_ = str(loss_)\n",
    "    msg = \"\\r Time_lapsed (hr:mm:ss) --> {0:02d}:{1:02d}:{2:02d} ,   loss: {3:s}   Log Progress: {4:.1%},     Overall Progress:{5:.1%},\" \\\n",
    "        \" completed {6:d} out of 185 logs <--> Initial loss: {7:s} \".format(hr, mint, sec, loss, percent_complete, overall_complete, count_log, loss_)\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "\n",
    "def validation_progress(log_cnt, num_logs, time_, loss, accuracy_loc):\n",
    "    log_cnt += 1\n",
    "    overall_complete = float(log_cnt) / num_logs\n",
    "    sec = int(time_) % 60\n",
    "    mint = int(time_/60) % 60\n",
    "    hr = int(time_/3600) % 60\n",
    "    loss = str(loss)\n",
    "    msg = \"\\r Validation_Time (hr:mm:ss) --> {0:02d}:{1:02d}:{2:02d} ,   Avg_loss: {3:s}   Avg_accuracy: {4:.2%}   Overall Progress:{5:.1%},\" \\\n",
    "        \" completed {6:d} out of {7:d} logs\".format(hr, mint, sec, loss, accuracy_loc, overall_complete, log_cnt, num_logs)\n",
    "    sys.stdout.write(colored(msg, 'green'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def write_summaries(loss, i, global_step, vars_loc, grads_loc, train=True):\n",
    "    with summary_writer.as_default():\n",
    "        with tf.contrib.summary.always_record_summaries():\n",
    "            if train:\n",
    "                tf.contrib.summary.scalar(\"train_loss\", loss, step=global_step)\n",
    "                tf.contrib.summary.scalar(\"step\", i, step=global_step)\n",
    "                #  do not add spaces after names\n",
    "                tf.contrib.summary.histogram(\"weights\", vars_loc, step=global_step)\n",
    "                tf.contrib.summary.histogram(\"gradients\", grads_loc, step=global_step)\n",
    "            else:\n",
    "                tf.contrib.summary.scalar(\"val_loss\", loss, step=global_step)\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_mod(img, cam, filename):\n",
    "  \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.axis(\"off\")\n",
    "    imgplot = plt.imshow(img)\n",
    "\n",
    "    cam = (cam*-1.0) + 1.0\n",
    "    cam_heatmap = np.array(cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET))\n",
    "    # plt.subplot(143)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    cam_heatmap = cam_heatmap/255.0\n",
    "\n",
    "    fin = (img*0.7) + (cam_heatmap*0.3)\n",
    "    imgplot = plt.imshow(fin)\n",
    "\n",
    "    plt.savefig(filename, dpi=600)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object does not appear to be a 8-bit string path or a Python file-like object",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-fbfb47ca5362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# scale 0 to 1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1367\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object does not appear to be a 8-bit string path or a Python file-like object"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# TRAINING CODE\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "start = time.time()\n",
    "performance_flag = True\n",
    "img_idx = 40  # image to visualize\n",
    "prediction_raw = []\n",
    "\n",
    "for (batch, (image, label, speed, lengths)) in (enumerate(sample_dataset)):\n",
    "    size = np.shape(label)[0]\n",
    "    labels = tf.reshape(label, [size, 1])\n",
    "    speeds = tf.reshape(speed, [size, 1])\n",
    "    log_length = tf.squeeze(lengths)\n",
    "    # images = tf.squeeze(image)\n",
    "    # images = tf.expand_dims(images)\n",
    "    images = tf.reshape(image, [1,96,144,3])\n",
    "    batch += 1\n",
    "    if batch >= img_idx and batch <= (img_idx+288):\n",
    "        step = tf.train.get_or_create_global_step()\n",
    "        cost, layer_conv = model(images, conv_out= True)\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(images)\n",
    "            cost, layer_conv = model(images, conv_out= True)\n",
    "            prediction_raw.append(cost)\n",
    "\n",
    "        gb_grad = tape.gradient(cost, images)\n",
    "        target_conv_layer_grad = tape.gradient(cost, layer_conv)\n",
    "        del tape\n",
    "        conv_first_grad = tf.exp(cost)*target_conv_layer_grad \t\n",
    "        #second_derivative\n",
    "        conv_second_grad = tf.exp(cost)*target_conv_layer_grad*target_conv_layer_grad \n",
    "    \n",
    "        #triple_derivative\n",
    "        conv_third_grad = tf.exp(cost)[0]*target_conv_layer_grad*target_conv_layer_grad*target_conv_layer_grad\n",
    "        global_sum = np.sum(tf.reshape(layer_conv[0],(-1,conv_first_grad[0].shape[2])), axis=0)\n",
    "       \n",
    "        alpha_num = conv_second_grad[0]\n",
    "        alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "        alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
    "        alphas = alpha_num/alpha_denom\n",
    "\n",
    "        weights = np.maximum(conv_first_grad[0], 0.0)\n",
    "        \n",
    "        alphas_thresholding = np.where(weights, alphas, 0.0)\n",
    "        \n",
    "        alpha_normalization_constant = np.sum(np.sum(alphas_thresholding, axis=0),axis=0)\n",
    "        alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
    "        alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "    \n",
    "    \n",
    "        \n",
    "        deep_linearization_weights = np.sum(tf.reshape((weights*alphas),(-1,conv_first_grad[0].shape[2])),axis=0)\n",
    "        \n",
    "        #print deep_linearizat0=eglmoprstvion_weights\n",
    "        grad_CAM_map = np.sum(deep_linearization_weights*layer_conv[0], axis=2)\n",
    "        \n",
    "        # Passing through ReLU\n",
    "        cam = np.maximum(grad_CAM_map, 0)\n",
    "        cam = cam / np.max(cam) # scale 0 to 1.0   \n",
    "    \n",
    "        cam = resize(cam, (480, 720))\n",
    "        # Passing through ReLU\n",
    "        cam = np.maximum(grad_CAM_map, 0)\n",
    "        \n",
    "        cam = cam / np.max(cam) # scale 0 to 1.0    \n",
    "        cam = resize(cam, (480, 720))\n",
    "        img = plt.imread(images_s[(img_idx-1)*Batch_size])\n",
    "        img2 = resize(img, (480, 720))\n",
    "        plt.imshow(img2)\n",
    "        visualize_mod(img2, cam, output_path)\n",
    "    if batch > img_idx:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
